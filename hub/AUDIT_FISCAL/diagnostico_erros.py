import pandas as pd
import re
from google.cloud import bigquery
from google.oauth2 import service_account
from googleapiclient.discovery import build

# Importa seus m√≥dulos
from config import BQ_TABLE_ID
from content_extractor import ContentExtractor
from reference_data import ReferenceLoader

KEY_FILE = 'credentials.json'


def get_credentials():
    return service_account.Credentials.from_service_account_file(
        KEY_FILE, scopes=['https://www.googleapis.com/auth/drive',
                          'https://www.googleapis.com/auth/spreadsheets',
                          'https://www.googleapis.com/auth/cloud-platform']
    )


def main():
    print("üïµÔ∏è INICIANDO DIAGN√ìSTICO DE ARQUIVOS N√ÉO IDENTIFICADOS...")
    creds = get_credentials()

    # 1. Carregar a Mem√≥ria (Planilha) para saber o que temos cadastrado
    ref_loader = ReferenceLoader(creds)
    ref_loader.load_data()

    # 2. Conectar no BigQuery e pegar os erros
    client = bigquery.Client(credentials=creds)

    # Pega os √∫ltimos 20 erros para n√£o demorar muito
    query = f"""
        SELECT id_arquivo, nome_arquivo, link_arquivo
        FROM `{BQ_TABLE_ID}`
        WHERE cnpj = 'NAO_DETECTADO' 
           OR cnpj = 'NAO_IDENTIFICADO'
        ORDER BY data_processamento DESC
        LIMIT 20
    """

    df_erros = client.query(query).to_dataframe()

    if df_erros.empty:
        print("‚úÖ Maravilha! N√£o h√° arquivos 'NAO_DETECTADO' no BigQuery recentemente.")
        return

    print(f"‚ö†Ô∏è Encontrados {len(df_erros)} arquivos problem√°ticos. Analisando um por um...\n")

    # Prepara o extrator
    service_drive = build('drive', 'v3', credentials=creds)
    extractor = ContentExtractor(service_drive, creds)

    for i, row in df_erros.iterrows():
        file_id = row['id_arquivo']
        file_name = row['nome_arquivo']

        print(f"--- üìÑ Analisando: {file_name} ---")
        print(f"    üîó Link: {row['link_arquivo']}")

        # Refaz a extra√ß√£o
        texto, cnpj_extraido, usou_ocr = extractor.process_file(file_id, file_name)

        # Limpa o texto para facilitar leitura no log
        texto_limpo = " ".join(texto.split()) if texto else ""

        print(f"    üëÅÔ∏è Usou OCR? {'SIM' if usou_ocr else 'N√ÉO (Texto Direto)'}")
        print(f"    üìù Texto Extra√≠do (Primeiros 200 caracteres):")
        print(f"       [{texto_limpo[:200]}...]")

        # An√°lise Forense
        # Procura qualquer sequ√™ncia de n√∫meros que pare√ßa CNPJ (14), IE ou IM (acima de 6 digitos)
        numeros_achados = re.findall(r'\d{6,14}', texto_limpo.replace('.', '').replace('/', '').replace('-', ''))

        encontrou_match = False

        print(f"    üîç N√∫meros encontrados no documento: {numeros_achados[:10]}...")  # Mostra s√≥ os 10 primeiros

        for num in numeros_achados:
            # Verifica se esse n√∫mero existe na nossa base (mesmo que o rob√¥ n√£o tenha pego antes)
            if num in ref_loader.fast_lookup:
                empresa = ref_loader.fast_lookup[num]
                print(f"    ‚úÖ MATCH ENCONTRADO NA BASE! O n√∫mero {num} pertence a:")
                print(f"       üè¢ {empresa['empresa']} (CNPJ: {empresa['cnpj']})")
                encontrou_match = True
                break

        if not encontrou_match:
            print("    ‚ùå NENHUM n√∫mero do documento bateu com a planilha.")
            print("       -> Hip√≥tese 1: O CNPJ/IM deste cliente n√£o est√° na planilha.")
            print("       -> Hip√≥tese 2: O OCR leu o n√∫mero errado (ex: leu 'O' em vez de '0').")
        else:
            print("    ‚ö†Ô∏è O n√∫mero est√° na planilha, mas o script principal falhou.")
            print("       -> Hip√≥tese: O regex principal pode estar muito restrito.")

        print("-" * 50)


if __name__ == "__main__":
    main()